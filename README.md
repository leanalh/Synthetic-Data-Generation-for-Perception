# Synthetic-Data-Generation-for-Perception

The foundation for this project comes from the structured learning I completed through NVIDIA's official Isaac Sim synthetic data course (DLI S-OV-30). The training covered the essentials of scene setup and asset management. And also offered practical guidance on semantic annotation strategies and of course the use of the Replicator extension.

The official notebooks and lab material set a clear starting point, but found there were subtle implementation details and workflow decisions that were best discovered through direct experimentation. By adapting the core examples, I was able to refine the process and address some of the more specific challenges that arose.

In a sense, the approach here may resemble the original NVIDIA pipeline, but most of the solutions reflect a combination of the courseâ€™s methodology and some situational adjustments made for portfolio relevance. This blend of formal instruction and tailored exploration, I believe, may suggest a pragmatic path for others working with synthetic data in vision applications.
